{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "\n",
    "\n",
    "\n",
    "首先导入数据处理包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加载并分割数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "images=train.iloc[:,1:]\n",
    "labels_flat=train.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对输入进行处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入数据的数量：(42000,784)\n",
      "输入数据的维度=>784\n",
      "图片的长=>28\n",
      "图片的高=>28\n",
      "结果的种类=>10\n"
     ]
    }
   ],
   "source": [
    "images=images.astype(np.float)\n",
    "#归一化处理\n",
    "images=np.multiply(images,1.0/255.0)\n",
    "print('输入数据的数量：(%g,%g)'% images.shape)\n",
    "image_size=images.shape[1]\n",
    "print('输入数据的维度=>%g'% image_size)\n",
    "image_width = image_height=np.ceil(np.sqrt(image_size))\n",
    "print('图片的长=>%g\\n图片的高=>%g'%(image_width,image_height))\n",
    "labels_count=np.unique(labels_flat).shape[0]\n",
    "print('结果的种类=>%g'%labels_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**进行One-hot编码**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结果的数量：(42000,10)\n"
     ]
    }
   ],
   "source": [
    "# 进行One-hot编码\n",
    "def dense_to_one_hot(labels_dense,num_classes):\n",
    "    num_labels=labels_dense.shape[0]\n",
    "    # 计算每一行所需要的偏移量\n",
    "    index_offset=np.arange(num_labels)*num_classes\n",
    "    labels_one_hot=np.zeros((num_labels,num_classes))\n",
    "    # 把一个n*n的矩阵看做是一个1*n²的行向量，进行赋值\n",
    "    labels_one_hot.flat[index_offset+labels_dense.ravel()]=1\n",
    "    # 得到one-hot\n",
    "    return labels_one_hot\n",
    "\n",
    "labels=dense_to_one_hot(labels_flat,labels_count)\n",
    "labels=labels.astype(np.uint8)\n",
    "print('结果的数量：(%g,%g)'%labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder('float',shape=[None,image_size])\n",
    "y=tf.placeholder('float', shape=[None, labels_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**把输入数据划分为训练集和验证集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2000个数据作为验证集、其他40000个做训练集\n",
    "VALIDATION_SIZE=2000\n",
    "\n",
    "validation_images=images[:VALIDATION_SIZE]\n",
    "validation_labels=labels[:VALIDATION_SIZE]\n",
    "\n",
    "train_images=images[VALIDATION_SIZE:]\n",
    "train_labels=labels[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对训练集进行分批**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "n_batch=len(train_images)/batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建神经网络模型\n",
    "\n",
    "我们的神经网络的超参数：\n",
    "\n",
    "    1. 激活函数：softmax\n",
    "    2. 损失函数：交叉熵\n",
    "    3. 优化方式：梯度下降\n",
    "    4. 输入层：784个节点，对应每个像素点。\n",
    "    5. 隐层：只有一个隐层，10个节点，同时作为输出层。\n",
    "    6. 输出层：就是隐层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\AI\\Configuration\\Anaconda3\\envs\\cv-nd\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-8-ac8c0a9a975f>:10: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 这个weights表示第一隐层只有10个节点\n",
    "weights=tf.Variable(tf.zeros([784,10]))\n",
    "# biases,偏差，相当于y=ax+b中的b\n",
    "biases=tf.Variable(tf.zeros([10]))\n",
    "# result,定义第一隐层的输出\n",
    "result=tf.matmul(x,weights)+biases\n",
    "# prediction，激活函数，对线性计算结果添加非线性内容。\n",
    "prediction=tf.nn.softmax(result)\n",
    "#创建损失函数了，以交叉熵的平均值来衡量\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "#用梯度下降法优化参数\n",
    "train_step=tf.train.GradientDescentOptimizer(0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化变量并运行\n",
    "\n",
    "我们的神经网络的超参数：\n",
    "\n",
    "    1. 初始化变量\n",
    "    2. 计算准确度\n",
    "    3. 在session中训练  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化变量\n",
    "init=tf.global_variables_initializer()\n",
    "#计算准确度\n",
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step=tf.Variable(0,name='global_step',trainable=False)\n",
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1轮，准确度为：0.7925\n",
      "第2轮，准确度为：0.808\n",
      "第3轮，准确度为：0.8155\n",
      "第4轮，准确度为：0.8535\n",
      "第5轮，准确度为：0.876\n",
      "第6轮，准确度为：0.8875\n",
      "WARNING:tensorflow:From D:\\AI\\Configuration\\Anaconda3\\envs\\cv-nd\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "第7轮，准确度为：0.8915\n",
      "第8轮，准确度为：0.895\n",
      "第9轮，准确度为：0.897\n",
      "第10轮，准确度为：0.897\n",
      "第11轮，准确度为：0.899\n",
      "第12轮，准确度为：0.9005\n",
      "第13轮，准确度为：0.901\n",
      "第14轮，准确度为：0.9035\n",
      "第15轮，准确度为：0.9065\n",
      "第16轮，准确度为：0.9075\n",
      "第17轮，准确度为：0.908\n",
      "第18轮，准确度为：0.909\n",
      "第19轮，准确度为：0.9105\n",
      "第20轮，准确度为：0.9105\n",
      "第21轮，准确度为：0.911\n",
      "第22轮，准确度为：0.911\n",
      "第23轮，准确度为：0.9115\n",
      "第24轮，准确度为：0.912\n",
      "第25轮，准确度为：0.9125\n",
      "第26轮，准确度为：0.9135\n",
      "第27轮，准确度为：0.9135\n",
      "第28轮，准确度为：0.9135\n",
      "第29轮，准确度为：0.9135\n",
      "第30轮，准确度为：0.914\n",
      "第31轮，准确度为：0.9145\n",
      "第32轮，准确度为：0.915\n",
      "第33轮，准确度为：0.915\n",
      "第34轮，准确度为：0.915\n",
      "第35轮，准确度为：0.916\n",
      "第36轮，准确度为：0.917\n",
      "第37轮，准确度为：0.918\n",
      "第38轮，准确度为：0.919\n",
      "第39轮，准确度为：0.919\n",
      "第40轮，准确度为：0.9195\n",
      "第41轮，准确度为：0.9195\n",
      "第42轮，准确度为：0.9195\n",
      "第43轮，准确度为：0.919\n",
      "第44轮，准确度为：0.9195\n",
      "第45轮，准确度为：0.9185\n",
      "第46轮，准确度为：0.919\n",
      "第47轮，准确度为：0.919\n",
      "第48轮，准确度为：0.919\n",
      "第49轮，准确度为：0.919\n",
      "第50轮，准确度为：0.9195\n"
     ]
    }
   ],
   "source": [
    "#在session中进行训练\n",
    "with tf.Session() as sess:\n",
    "    # 初始化变量\n",
    "    sess.run(init)\n",
    "    \n",
    "    # 循环50轮\n",
    "    for epoch in range(50):\n",
    "        for batch in range(int(n_batch)):\n",
    "            # 按照batch取出数据\n",
    "            batch_x=train_images[batch*batch_size:(batch+1)*batch_size]\n",
    "            batch_y=train_labels[batch*batch_size:(batch+1)*batch_size]\n",
    "            # 开始训练\n",
    "            sess.run(train_step,feed_dict={x:batch_x,y:batch_y})\n",
    "        # 每一轮训练计算结果\n",
    "        accuracy_n=sess.run(accuracy,feed_dict={x:validation_images,y:validation_labels})\n",
    "        # 打印结果\n",
    "        print(\"第\"+str(epoch+1)+\"轮，准确度为：\"+str(accuracy_n))\n",
    "        # 保存训练模型\n",
    "        global_step.assign(epoch).eval()\n",
    "        saver.save(sess,\"save/model.ckpt\",global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#现在可以开始对测试集进行预处理了\n",
    "test=pd.read_csv('test.csv',index_col=False)\n",
    "test_x=test.iloc[:,1:].values\n",
    "test_x=test_x.astype(np.float)\n",
    "test_x=np.multiply(test_x,1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\AI\\Configuration\\Anaconda3\\envs\\cv-nd\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from save/model.ckpt-49\n"
     ]
    }
   ],
   "source": [
    "#我们用我们训练好的模型开始预测，把结果写入到Digit1.csv\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    saver.restore(sess,'save/model.ckpt-49')\n",
    "    \n",
    "    test_x=np.array(test,dtype=np.float32)\n",
    "    \n",
    "    y_predict=prediction.eval(feed_dict={x:test_x[1:100,:]})\n",
    "    y_predict_all=list()\n",
    "    \n",
    "    for i in np.arange(100,28001,100):\n",
    "        \n",
    "        y_predict=prediction.eval(feed_dict={x:test_x[i-100:i,:]})\n",
    "        \n",
    "        test_pred=np.argmax(y_predict,axis=1)\n",
    "        \n",
    "        y_predict_all=np.append(y_predict_all,test_pred)\n",
    "    \n",
    "    submission=pd.DataFrame(data={'ImageId':range(1,28001),'Label':np.int32(y_predict_all)})\n",
    "    \n",
    "    submission.to_csv('Digit1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-nd",
   "language": "python",
   "name": "cv-nd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "802px",
    "left": "0px",
    "right": "953.28125px",
    "top": "110px",
    "width": "371px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
